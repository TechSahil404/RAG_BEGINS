import os
import fitz
import tabula
from PIL import Image
import pytesseract
import streamlit as st
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline
# langchain_community.document_loaders ‡§ï‡•Ä ‡§Ö‡§¨ ‡§ú‡§∞‡•Ç‡§∞‡§§ ‡§®‡§π‡•Ä‡§Ç
from langchain_text_splitters import RecursiveCharacterTextSplitter
# HuggingFaceEmbeddings ‡§ï‡§æ ‡§á‡§Æ‡•ç‡§™‡•ã‡§∞‡•ç‡§ü ‡§¨‡§¶‡§≤‡§æ ‡§ó‡§Ø‡§æ
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.schema import Document
# HuggingFacePipeline ‡§ï‡§æ ‡§á‡§Æ‡•ç‡§™‡•ã‡§∞‡•ç‡§ü ‡§¨‡§¶‡§≤‡§æ ‡§ó‡§Ø‡§æ
from langchain_huggingface import HuggingFacePipeline
from langchain.chains import RetrievalQA

# --- Tesseract-OCR ‡§ï‡§æ ‡§™‡§æ‡§• ‡§Ø‡§π‡§æ‡§Å ‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç ---
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

# --- UI ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ü‡§æ‡§á‡§ü‡§≤ ‡§î‡§∞ ‡§π‡•á‡§°‡§∞ ---
st.set_page_config(page_title="PDF ‡§∏‡•á ‡§™‡•Ç‡§õ‡•á‡§Ç", layout="wide")
st.title("üìÑ PDF ‡§∏‡•á ‡§∏‡§µ‡§æ‡§≤-‡§ú‡§µ‡§æ‡§¨ ‡§ï‡§∞‡•á‡§Ç")

# --- ‡§ï‡•à‡§∂‡§ø‡§Ç‡§ó ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§™‡§∞‡§´‡•â‡§∞‡§Æ‡•á‡§Ç‡§∏ ‡§∏‡•Å‡§ß‡§æ‡§∞ ---
# ‡§Ø‡§π ‡§´‡§Ç‡§ï‡•ç‡§∂‡§® ‡§∏‡§ø‡§∞‡•ç‡§´ ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§ö‡§≤‡•á‡§ó‡§æ ‡§î‡§∞ ‡§∞‡§ø‡§ú‡§≤‡•ç‡§ü ‡§ï‡•ã ‡§Æ‡•á‡§Æ‡•ã‡§∞‡•Ä ‡§Æ‡•á‡§Ç ‡§∞‡§ñ‡•á‡§ó‡§æ
@st.cache_resource
def create_rag_pipeline(pdf_path):
    """
    ‡§™‡•Ç‡§∞‡•Ä RAG ‡§™‡§æ‡§á‡§™‡§≤‡§æ‡§á‡§® ‡§¨‡§®‡§æ‡§§‡§æ ‡§π‡•à ‡§î‡§∞ ‡§á‡§∏‡•á ‡§ï‡•à‡§∂ ‡§Æ‡•á‡§Ç ‡§∏‡•ç‡§ü‡•ã‡§∞ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§
    """
    if not os.path.exists(pdf_path):
        st.error(f"‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: '{pdf_path}' ‡§´‡§æ‡§á‡§≤ ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä‡•§")
        return None

    # --- 1. ‡§°‡•á‡§ü‡§æ ‡§≤‡•ã‡§°‡§∞ ---
    with st.spinner(f"'{pdf_path}' ‡§∏‡•á ‡§°‡•á‡§ü‡§æ ‡§®‡§ø‡§ï‡§æ‡§≤‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à..."):
        all_text = []
        try:
            doc = fitz.open(pdf_path)
            for page_num, page in enumerate(doc):
                all_text.append(page.get_text("text"))
                pix = page.get_pixmap(dpi=200) # ‡§§‡•á‡§ú ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§≤‡§ø‡§è DPI ‡§ï‡§Æ ‡§ï‡§ø‡§Ø‡§æ
                img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                ocr_text = pytesseract.image_to_string(img)
                if ocr_text.strip():
                    all_text.append(ocr_text)
            
            tables = tabula.read_pdf(pdf_path, pages="all", multiple_tables=True)
            if tables:
                for table in tables:
                    all_text.append(table.to_string(index=False))
        except Exception as e:
            st.warning(f"‡§°‡•á‡§ü‡§æ ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡•á ‡§Æ‡•á‡§Ç ‡§ï‡•Å‡§õ ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•Å‡§à: {e}")
        
        docs = [Document(page_content="\n".join(all_text))]

    # --- 2. ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§ö‡§Ç‡§ï‡§ø‡§Ç‡§ó ---
    with st.spinner("‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§ï‡•ã ‡§ü‡•Å‡§ï‡§°‡§º‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§§‡•ã‡§°‡§º‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à..."):
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        chunks = text_splitter.split_documents(docs)

    # --- 3. ‡§è‡§Æ‡•ç‡§¨‡•á‡§°‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§µ‡•á‡§ï‡•ç‡§ü‡§∞ DB ---
    with st.spinner("‡§è‡§Æ‡•ç‡§¨‡•á‡§°‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§µ‡•á‡§ï‡•ç‡§ü‡§∞ ‡§∏‡•ç‡§ü‡•ã‡§∞ ‡§¨‡§®‡§æ‡§Ø‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à..."):
        embeddings_model = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-mpnet-base-v2",
            model_kwargs={'device': 'cpu'}
        )
        vector_store = FAISS.from_documents(documents=chunks, embedding=embeddings_model)

    # --- 4. LLM (CPU-‡§´‡•ç‡§∞‡•á‡§Ç‡§°‡§≤‡•Ä) ---
    with st.spinner("CPU-‡§´‡•ç‡§∞‡•á‡§Ç‡§°‡§≤‡•Ä ‡§Æ‡•â‡§°‡§≤ ‡§≤‡•ã‡§° ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à..."):
        # <<--- ‡§Ø‡§π‡§æ‡§Å CPU-‡§´‡•ç‡§∞‡•á‡§Ç‡§°‡§≤‡•Ä ‡§Æ‡•â‡§°‡§≤ ‡§∏‡•á‡§ü ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à ---<<
        model_name = "google/flan-t5-small"
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
        
        pipe = pipeline("text2text-generation", model=model, tokenizer=tokenizer, max_new_tokens=256)
        llm = HuggingFacePipeline(pipeline=pipe)
    
    # --- 5. Q&A ‡§ö‡•á‡§® ---
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=vector_store.as_retriever(search_kwargs={"k": 3}), # 3 ‡§∏‡§¨‡§∏‡•á ‡§™‡•ç‡§∞‡§æ‡§∏‡§Ç‡§ó‡§ø‡§ï ‡§ü‡•Å‡§ï‡§°‡§º‡•á ‡§¢‡•Ç‡§Ç‡§¢‡•á‡§ó‡§æ
        return_source_documents=True
    )
    
    st.success("--- RAG ‡§™‡§æ‡§á‡§™‡§≤‡§æ‡§á‡§® ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•à! ---")
    return qa_chain

# --- ‡§Æ‡•Å‡§ñ‡•ç‡§Ø UI ‡§≤‡•â‡§ú‡§ø‡§ï ---
pdf_file_path = "attention.pdf"
rag_pipeline = create_rag_pipeline(pdf_file_path)

if rag_pipeline:
    st.header(f"‡§Ö‡§¨ ‡§Ü‡§™ '{pdf_file_path}' ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç")
    query = st.text_input("‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§Ø‡§π‡§æ‡§Å ‡§≤‡§ø‡§ñ‡•á‡§Ç:", placeholder="What is the main idea of this document?")

    if st.button("‡§ú‡§µ‡§æ‡§¨ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡•á‡§Ç"):
        if query.strip():
            with st.spinner("‡§ú‡§µ‡§æ‡§¨ ‡§¢‡•Ç‡§Ç‡§¢‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à..."):
                try:
                    result = rag_pipeline({"query": query})
                    st.subheader("‡§â‡§§‡•ç‡§§‡§∞:")
                    st.write(result['result'])

                    # ‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§°‡•â‡§ï‡•ç‡§Ø‡•Ç‡§Æ‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§¶‡§ø‡§ñ‡§æ‡§®‡•á ‡§ï‡§æ ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™
                    with st.expander("‡§â‡§§‡•ç‡§§‡§∞ ‡§ï‡§π‡§æ‡§Å ‡§∏‡•á ‡§Æ‡§ø‡§≤‡§æ? (‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§¶‡•á‡§ñ‡•á‡§Ç)"):
                        for doc in result['source_documents']:
                            st.info(doc.page_content)
                except Exception as e:
                    st.error(f"‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§§‡•á ‡§∏‡§Æ‡§Ø ‡§è‡§ï ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§π‡•Å‡§à: {e}")
        else:
            st.warning("‡§ï‡•É‡§™‡§Ø‡§æ ‡§ï‡•ã‡§à ‡§∏‡§µ‡§æ‡§≤ ‡§¶‡§∞‡•ç‡§ú ‡§ï‡§∞‡•á‡§Ç‡•§")

